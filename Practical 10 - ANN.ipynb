{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Practical 10 - ANN.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1tkPba-sGob5-7j9cKL5FAi8PqyJAqw7_","authorship_tag":"ABX9TyPJ5jZML0ZIUSkpjLiEgaMW"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"rmlAZNfOaB4K"},"source":["from google.colab import drive"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8Q_jhFuodgU8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1604480060960,"user_tz":-330,"elapsed":1373,"user":{"displayName":"SHREY ARORA","photoUrl":"","userId":"10548180523723076734"}},"outputId":"36a15e34-cfbf-4801-b034-c6b424cab5eb"},"source":["import pandas as pd\n","df=pd.read_csv(\"/content/drive/My Drive/CSV FILES/BankNote.csv\")\n","print(df.head(10))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["    3.6216  8.6661  -2.8073  -0.44699  0\n","0  4.54590  8.1674 -2.45860  -1.46210  0\n","1  3.86600 -2.6383  1.92420   0.10645  0\n","2  3.45660  9.5228 -4.01120  -3.59440  0\n","3  0.32924 -4.4552  4.57180  -0.98880  0\n","4  4.36840  9.6718 -3.96060  -3.16250  0\n","5  3.59120  3.0129  0.72888   0.56421  0\n","6  2.09220 -6.8100  8.46360  -0.60216  0\n","7  3.20320  5.7588 -0.75345  -0.61251  0\n","8  1.53560  9.1772 -2.27180  -0.73535  0\n","9  1.22470  8.7779 -2.21350  -0.80647  0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"cVjMQ7KzamGt","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1604479902612,"user_tz":-330,"elapsed":61063,"user":{"displayName":"SHREY ARORA","photoUrl":"","userId":"10548180523723076734"}},"outputId":"10bbad52-7360-4477-c872-c3ae66abbeb8"},"source":["# Backprop on the Seeds Dataset\n","from random import seed\n","from random import randrange\n","from random import random\n","from csv import reader\n","from math import exp\n","\n","filename=\"/content/drive/My Drive/CSV FILES/BankNote.csv\"\n"," \n","# Load a CSV file\n","def load_csv(filename):\n","\tdataset = list()\n","\twith open(filename, 'r') as file:\n","\t\tcsv_reader = reader(file)\n","\t\tfor row in csv_reader:\n","\t\t\tif not row:\n","\t\t\t\tcontinue\n","\t\t\tdataset.append(row)\n","\treturn dataset\n"," \n","# Convert string column to float\n","def str_column_to_float(dataset, column):\n","\tfor row in dataset:\n","\t\trow[column] = float(row[column].strip())\n"," \n","# Convert string column to integer\n","def str_column_to_int(dataset, column):\n","\tclass_values = [row[column] for row in dataset]\n","\tunique = set(class_values)\n","\tlookup = dict()\n","\tfor i, value in enumerate(unique):\n","\t\tlookup[value] = i\n","\tfor row in dataset:\n","\t\trow[column] = lookup[row[column]]\n","\treturn lookup\n"," \n","# Find the min and max values for each column\n","def dataset_minmax(dataset):\n","\tminmax = list()\n","\tstats = [[min(column), max(column)] for column in zip(*dataset)]\n","\treturn stats\n"," \n","# Rescale dataset columns to the range 0-1\n","def normalize_dataset(dataset, minmax):\n","\tfor row in dataset:\n","\t\tfor i in range(len(row)-1):\n","\t\t\trow[i] = (row[i] - minmax[i][0]) / (minmax[i][1] - minmax[i][0])\n"," \n","# Split a dataset into k folds\n","def cross_validation_split(dataset, n_folds):\n","\tdataset_split = list()\n","\tdataset_copy = list(dataset)\n","\tfold_size = int(len(dataset) / n_folds)\n","\tfor i in range(n_folds):\n","\t\tfold = list()\n","\t\twhile len(fold) < fold_size:\n","\t\t\tindex = randrange(len(dataset_copy))\n","\t\t\tfold.append(dataset_copy.pop(index))\n","\t\tdataset_split.append(fold)\n","\treturn dataset_split\n"," \n","# Calculate accuracy percentage\n","def accuracy_metric(actual, predicted):\n","\tcorrect = 0\n","\tfor i in range(len(actual)):\n","\t\tif actual[i] == predicted[i]:\n","\t\t\tcorrect += 1\n","\treturn correct / float(len(actual)) * 100.0\n"," \n","# Evaluate an algorithm using a cross validation split\n","def evaluate_algorithm(dataset, algorithm, n_folds, *args):\n","\tfolds = cross_validation_split(dataset, n_folds)\n","\tscores = list()\n","\tfor fold in folds:\n","\t\ttrain_set = list(folds)\n","\t\ttrain_set.remove(fold)\n","\t\ttrain_set = sum(train_set, [])\n","\t\ttest_set = list()\n","\t\tfor row in fold:\n","\t\t\trow_copy = list(row)\n","\t\t\ttest_set.append(row_copy)\n","\t\t\trow_copy[-1] = None\n","\t\tpredicted = algorithm(train_set, test_set, *args)\n","\t\tactual = [row[-1] for row in fold]\n","\t\taccuracy = accuracy_metric(actual, predicted)\n","\t\tscores.append(accuracy)\n","\treturn scores\n"," \n","# Calculate neuron activation for an input\n","def activate(weights, inputs):\n","\tactivation = weights[-1]\n","\tfor i in range(len(weights)-1):\n","\t\tactivation += weights[i] * inputs[i]\n","\treturn activation\n"," \n","# Transfer neuron activation\n","def transfer(activation):\n","\treturn 1.0 / (1.0 + exp(-activation))\n"," \n","# Forward propagate input to a network output\n","def forward_propagate(network, row):\n","\tinputs = row\n","\tfor layer in network:\n","\t\tnew_inputs = []\n","\t\tfor neuron in layer:\n","\t\t\tactivation = activate(neuron['weights'], inputs)\n","\t\t\tneuron['output'] = transfer(activation)\n","\t\t\tnew_inputs.append(neuron['output'])\n","\t\tinputs = new_inputs\n","\treturn inputs\n"," \n","# Calculate the derivative of an neuron output\n","def transfer_derivative(output):\n","\treturn output * (1.0 - output)\n"," \n","# Backpropagate error and store in neurons\n","def backward_propagate_error(network, expected):\n","\tfor i in reversed(range(len(network))):\n","\t\tlayer = network[i]\n","\t\terrors = list()\n","\t\tif i != len(network)-1:\n","\t\t\tfor j in range(len(layer)):\n","\t\t\t\terror = 0.0\n","\t\t\t\tfor neuron in network[i + 1]:\n","\t\t\t\t\terror += (neuron['weights'][j] * neuron['delta'])\n","\t\t\t\terrors.append(error)\n","\t\telse:\n","\t\t\tfor j in range(len(layer)):\n","\t\t\t\tneuron = layer[j]\n","\t\t\t\terrors.append(expected[j] - neuron['output'])\n","\t\tfor j in range(len(layer)):\n","\t\t\tneuron = layer[j]\n","\t\t\tneuron['delta'] = errors[j] * transfer_derivative(neuron['output'])\n"," \n","# Update network weights with error\n","def update_weights(network, row, l_rate):\n","\tfor i in range(len(network)):\n","\t\tinputs = row[:-1]\n","\t\tif i != 0:\n","\t\t\tinputs = [neuron['output'] for neuron in network[i - 1]]\n","\t\tfor neuron in network[i]:\n","\t\t\tfor j in range(len(inputs)):\n","\t\t\t\tneuron['weights'][j] += l_rate * neuron['delta'] * inputs[j]\n","\t\t\tneuron['weights'][-1] += l_rate * neuron['delta']\n"," \n","# Train a network for a fixed number of epochs\n","def train_network(network, train, l_rate, n_epoch, n_outputs):\n","\tfor epoch in range(n_epoch):\n","\t\tfor row in train:\n","\t\t\toutputs = forward_propagate(network, row)\n","\t\t\texpected = [0 for i in range(n_outputs)]\n","\t\t\texpected[row[-1]] = 1\n","\t\t\tbackward_propagate_error(network, expected)\n","\t\t\tupdate_weights(network, row, l_rate)\n"," \n","# Initialize a network\n","def initialize_network(n_inputs, n_hidden, n_outputs):\n","\tnetwork = list()\n","\thidden_layer = [{'weights':[random() for i in range(n_inputs + 1)]} for i in range(n_hidden)]\n","\tnetwork.append(hidden_layer)\n","\toutput_layer = [{'weights':[random() for i in range(n_hidden + 1)]} for i in range(n_outputs)]\n","\tnetwork.append(output_layer)\n","\treturn network\n"," \n","# Make a prediction with a network\n","def predict(network, row):\n","\toutputs = forward_propagate(network, row)\n","\treturn outputs.index(max(outputs))\n"," \n","# Backpropagation Algorithm With Stochastic Gradient Descent\n","def back_propagation(train, test, l_rate, n_epoch, n_hidden):\n","\tn_inputs = len(train[0]) - 1\n","\tn_outputs = len(set([row[-1] for row in train]))\n","\tnetwork = initialize_network(n_inputs, n_hidden, n_outputs)\n","\ttrain_network(network, train, l_rate, n_epoch, n_outputs)\n","\tpredictions = list()\n","\tfor row in test:\n","\t\tprediction = predict(network, row)\n","\t\tpredictions.append(prediction)\n","\treturn(predictions)\n"," \n","# Test Backprop on Seeds dataset\n","seed(1)\n","# load and prepare data\n","filename = 'BankNote.csv'\n","dataset = load_csv(\"/content/drive/My Drive/CSV FILES/BankNote.csv\")\n","for i in range(len(dataset[0])-1):\n","\tstr_column_to_float(dataset, i)\n","# convert class column to integers\n","str_column_to_int(dataset, len(dataset[0])-1)\n","# normalize input variables\n","minmax = dataset_minmax(dataset)\n","normalize_dataset(dataset, minmax)\n","# evaluate algorithm\n","n_folds = 5\n","l_rate = 0.3\n","n_epoch = 500\n","n_hidden = 5\n","scores = evaluate_algorithm(dataset, back_propagation, n_folds, l_rate, n_epoch, n_hidden)\n","print('Scores: %s' % scores)\n","print('Mean Accuracy: %.3f%%' % (sum(scores)/float(len(scores))))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Scores: [100.0, 100.0, 100.0, 100.0, 100.0]\n","Mean Accuracy: 100.000%\n"],"name":"stdout"}]}]}